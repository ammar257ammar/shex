# ShEx Telecons

## Telecon 2018-08-30  Minutes

* Participants: Kat, Andra, Tom, ericP, Dimitris, Gregg, Lucas
* Regrets: Harold

Call in Zoom # https://zoom.us/j/441496948

* Chair: Dimitris
* Scribe: Kat, ericP

### Community updates

* Kat: noticed Jose is giving a [ShEx] tutorial at ISWC2018
* Dimitris: I'm giving a talk in connected data london  Will be more high-level but will mention ShEx.
* ericP: Observable notebook (similar to Jupyter) for ShEx validation: https://beta.observablehq.com/@ericprud/shex-validator
* Tom: What is Observable?
* ericP: like Jupyter for javascript- can use as an example for Colab- to show them what we'd like to be able to do in Colab
* Tom: Advantage of Juypetr notebook is that you can save it and share it. You can slide things up and down. Is this also possible with this tool? Can you save the results in json?
* ericP: It does version control itself- you can download a tarball and you can download code from the interface. I haven't played with downloading or re-uploading downloaded code.

### Wikibase New York

* Andra: Jose and I will go to the WikiBase workshop.
* ... We'll work on visualizations of ShEx as well as visual authoring tools for ShEx.

### SWIB/WikiCite event conflict

* Andra: We have a conflict because SWIB and Wikicite overlap, and then SWAT4LS is just one week later and we may also do a tutorial there. Maybe even a shex hackathon.
* ... deadline for WikiCite proposals is Sept 17. What will we propose?
* ericP: develop tools and document how wikidata uses shex- Joachim. WOuld be good to work with Jose to get his implementation working with Blazegraph. Would be cool to run shex over the property graph directly. Validation directly over the initial property graph. Duplicate code that makes the image- we would need shex db emulator to get the triples.
* Andra: I've attended previous WikiCite's (met Kat there). You submit a presentation to get accepted and once there, propose a topic for the hackathon. What would we present? The WikiBase WS in Berlin? DIEGO? Lucas's wikidata item -> ShEx tool?
* Kat: +1 (to all three)
* Andra: Who is going to SWAT4LS and should we think about a ShEx hackathon?

### Resolutions and Notes for 2.1 doc

* Dimitris: Kat created a doc for all of the resolutions since 2.0.
* https://hackmd.io/POx2h6lGQ--SXErxZLRSXw?edit
* Dimitris: can someone update me on the discussion on where we are in terms of releasing 2.1
* ericp: 1. publishing semantics for recursive validation (one caveat: we may be able to get rid of one rule) 2. Simplifying grammar 3. Enhancements: lang tag value sets, and Import
... I'm going through the grammar I have implemented to make sure it is consistent w spec
* Dimitris: Peter expressed his preference is not to review things before they are public- because he's not part of WG

### Issue Tracker Cleanup
* Dimitris: Labels, 2.1, what is for later?
* ericP: we have a 2.1 tag, let's create a 2.2 tag and decide if we're doing it now or later. Or 2.next tag or later tag https://github.com/shexSpec/shex/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+milestone%3A2.1
* Dimitris: Anyone have ideas for how we can do this?

### Test suite

* ericP: We need to approve tests this time. Some facets we used only in development. Somebody else run the tests as well. Everything that two people have validated we mark as approved. The others we mark as pending. The ones that are specifically using contrary semantics from the experimentation phase with something like rejected. That counts on someone other than eric generating an early set of reports and lining up the test suites. Ask Gregg for an implementation report. 
* Gregg: It is a gem that anyone can run.
* ericP: manifest format we are using for the tests came from data access working group- subsumed by manifest format several of us share for demos, etc. Since several of us are using that as part of our maintained codebase- might be nice to migrate the test format. I have something that converts from one to the other. 
* Gregg: SPARQL needs to be customized for each. Then it needs for each implementation report that lists relevant information for each test. 
* ericP: I wonder how close it is to our manifest format?
* Gregg: We can work on this offline.
* Dimitris: Any other comments on the test suite?

### Dataset Support

* ericP: I responded to your challenge for the motivating use cases for the JSONLD 1.1 wg. https://github.com/w3c/json-ld-api/issues/26
* Gregg: Graph containers weren't in 1.0. Proposal is if you use a graph container then the name is the same as the bnode that is object portion of original statement.
* ericP: If that passes or something like it in JSONLD 1.1, then we have a more constrained problem for dataset validation. We won't need SPARQL in the middle to find nested graphs, because JSONLD will point to the interesting bits in the nested graphs.
